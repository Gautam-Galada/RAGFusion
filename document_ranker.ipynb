{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from operator import itemgetter\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from fpdf import FPDF\n",
    "from PyPDF2 import PdfFileMerger, PdfFileReader\n",
    "import os\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings.sentence_transformer import (SentenceTransformerEmbeddings,)\n",
    "from langchain_text_splitters import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG_Pipeline:\n",
    "    def __init__(self, default_model=\"llama2\", doc=\"test.pdf\"):\n",
    "        self.model_name=default_model\n",
    "        self.doc_path=doc\n",
    "        self.model=Ollama(model=self.model_name)\n",
    "        self.embeddings=OllamaEmbeddings()\n",
    "        self.parser=StrOutputParser()\n",
    "        self.loader=PyPDFLoader(self.doc_path)\n",
    "        self.pages=self.loader.load_and_split()\n",
    "        self.vectorstore=DocArrayInMemorySearch.from_documents(self.pages,embedding=self.embeddings)\n",
    "        self.retriever=self.vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "        self.prompt_template = \"\"\"\n",
    "        Answer the question based on the context below. If you cannot answer the question, reply \"I don't know\".\n",
    "\n",
    "        Context: {context}\n",
    "\n",
    "        Question: Who is the best suited for the project {question}, say the name and explain why that person is best suited for this project\n",
    "        \"\"\"\n",
    "        self.prompt = PromptTemplate.from_template(self.prompt_template)\n",
    "        self.chain = (\n",
    "            {\n",
    "                \"context\": itemgetter(\"question\") | self.retriever, \n",
    "                \"question\": itemgetter(\"question\")\n",
    "            }\n",
    "            | self.prompt | self.model | self.parser\n",
    "        )\n",
    "    def fetch(self, question):return self.chain.invoke({'question': question})\n",
    "    def get_metadata_for_chunk(self, chunk_id):\n",
    "        metadata = self.vectorstore.get_metadata(chunk_id)\n",
    "        return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RAG_Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path='data'\n",
    "output_folder='extract'\n",
    "\n",
    "os.makedirs(output_folder,exist_ok=True)\n",
    "user_input = \"\"\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".pdf\") or filename.endswith(\".docx\"): \n",
    "        file_path=os.path.join(folder_path, filename)\n",
    "        model=RAG_Pipeline(doc=file_path)\n",
    "        answer=model.fetch(user_input)\n",
    "        output_file_path=os.path.join(output_folder,f\"{os.path.splitext(filename)[0]}_answer.txt\")\n",
    "        with open(output_file_path, 'w') as outfile:outfile.write(answer + \"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"extract\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_score=float('-inf')\n",
    "best_file=None\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path=os.path.join(folder_path, filename)\n",
    "        loader=TextLoader(file_path)\n",
    "        documents=loader.load()\n",
    "        docs=text_splitter.split_documents(documents)\n",
    "        db=Chroma.from_documents(docs, embedding_function)\n",
    "        docs=db.similarity_search(query)\n",
    "        sml_scr=db.similarity_search_with_score(query)\n",
    "        _, val=sml_scr[0]\n",
    "        if val >highest_score:\n",
    "            highest_score=val\n",
    "            best_file=filename\n",
    "print(f\"File name is: {best_file} | score of : {highest_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
